name: ML Training Pipeline

on:
  push:
    branches:
      - main
      - develop
    paths:
      - 'MLProject/**'
      - '.github/workflows/main.yml'
  pull_request:
    branches:
      - main
      - develop
    paths:
      - 'MLProject/**'
  workflow_dispatch:
    inputs:
      model_type:
        description: 'Model to train (all, Logistic_Regression, Random_Forest, Gradient_Boosting, Decision_Tree, K_Nearest_Neighbors, Support_Vector_Machine)'
        required: false
        default: 'all'

jobs:
  setup:
    name: Setup Environment
    runs-on: ubuntu-latest
    outputs:
      python-version: ${{ steps.setup-python.outputs.python-version }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python 3.12.7
        id: setup-python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12.7'
      
      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('MLProject/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r MLProject/requirements.txt
      
      - name: Verify dataset
        run: |
          if [ ! -f "MLProject/Heart_Disease_preprocessing.csv" ]; then
            echo "‚ùå Dataset not found!"
            exit 1
          fi
          echo "‚úÖ Dataset found"
          python -c "import pandas as pd; df = pd.read_csv('MLProject/Heart_Disease_preprocessing.csv'); print(f'Dataset shape: {df.shape}')"

  train:
    name: Train ML Models
    needs: setup
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        model: [
          'Logistic_Regression',
          'Random_Forest',
          'Gradient_Boosting',
          'Decision_Tree',
          'K_Nearest_Neighbors',
          'Support_Vector_Machine'
        ]
      fail-fast: false
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python 3.12.7
        uses: actions/setup-python@v5
        with:
          python-version: '3.12.7'
      
      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('MLProject/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r MLProject/requirements.txt
      
      - name: Train model - ${{ matrix.model }}
        run: |
          cd MLProject
          python modelling.py --model ${{ matrix.model }}
        env:
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
          MLFLOW_TRACKING_USERNAME: ${{ secrets.MLFLOW_TRACKING_USERNAME }}
          MLFLOW_TRACKING_PASSWORD: ${{ secrets.MLFLOW_TRACKING_PASSWORD }}
      
      - name: Upload model artifacts
        uses: actions/upload-artifact@v4
        with:
          name: model-${{ matrix.model }}
          path: |
            MLProject/mlruns/
            MLProject/model_comparison_results.csv
          retention-days: 30
      
      - name: Upload training logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: logs-${{ matrix.model }}
          path: MLProject/*.log
          retention-days: 7
          if-no-files-found: ignore

  evaluate:
    name: Evaluate and Compare Models
    needs: train
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python 3.12.7
        uses: actions/setup-python@v5
        with:
          python-version: '3.12.7'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas numpy matplotlib seaborn
      
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/
      
      - name: Compare model results
        run: |
          python -c "
          import pandas as pd
          import os
          import glob
          
          # Find all result CSV files
          csv_files = glob.glob('artifacts/**/model_comparison_results.csv', recursive=True)
          
          if csv_files:
              # Combine results
              dfs = [pd.read_csv(f) for f in csv_files]
              combined = pd.concat(dfs, ignore_index=True)
              combined = combined.sort_values('test_accuracy', ascending=False)
              
              print('='*70)
              print('üìä MODEL COMPARISON RESULTS')
              print('='*70)
              print(combined.to_string(index=False))
              print('='*70)
              
              # Save combined results
              combined.to_csv('final_model_comparison.csv', index=False)
              
              # Best model
              best_model = combined.iloc[0]
              print(f\"\\nüèÜ BEST MODEL: {best_model['model']}\")
              print(f\"   Accuracy: {best_model['test_accuracy']:.4f}\")
              print(f\"   Precision: {best_model['test_precision']:.4f}\")
              print(f\"   Recall: {best_model['test_recall']:.4f}\")
              print(f\"   F1-Score: {best_model['test_f1_score']:.4f}\")
          else:
              print('‚ùå No result files found!')
          "
      
      - name: Upload final comparison
        uses: actions/upload-artifact@v4
        with:
          name: final-comparison
          path: final_model_comparison.csv
          retention-days: 90
      
      - name: Create summary
        run: |
          echo "## üéØ ML Training Pipeline Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Models Trained:" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Logistic Regression" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Random Forest" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Gradient Boosting" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Decision Tree" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ K-Nearest Neighbors" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Support Vector Machine" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "final_model_comparison.csv" ]; then
            echo "### üìä Model Performance:" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            cat final_model_comparison.csv >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: Prepare artifacts for commit
        run: |
          mkdir -p artifacts_permanent
          
          # Copy final comparison
          if [ -f "final_model_comparison.csv" ]; then
            cp final_model_comparison.csv artifacts_permanent/
          fi
          
          # Copy all downloaded artifacts
          if [ -d "artifacts" ]; then
            cp -r artifacts/* artifacts_permanent/
          fi
          
          # Create timestamp and metadata
          echo "# Training Run - $(date '+%Y-%m-%d %H:%M:%S')" > artifacts_permanent/README.md
          echo "" >> artifacts_permanent/README.md
          echo "**Commit:** ${{ github.sha }}" >> artifacts_permanent/README.md
          echo "**Branch:** ${{ github.ref_name }}" >> artifacts_permanent/README.md
          echo "**Workflow:** ${{ github.run_id }}" >> artifacts_permanent/README.md
          echo "**Triggered by:** ${{ github.actor }}" >> artifacts_permanent/README.md
          echo "" >> artifacts_permanent/README.md
          echo "## Results" >> artifacts_permanent/README.md
          if [ -f "final_model_comparison.csv" ]; then
            echo '```' >> artifacts_permanent/README.md
            cat final_model_comparison.csv >> artifacts_permanent/README.md
            echo '```' >> artifacts_permanent/README.md
          fi
      
      - name: Commit artifacts to artifacts branch
        run: |
          git config --global user.name "GitHub Actions Bot"
          git config --global user.email "actions@github.com"
          
          # Checkout or create artifacts branch
          git fetch origin artifacts || true
          git checkout -B artifacts || git checkout --orphan artifacts
          
          # Clear existing content (keep only new artifacts)
          git rm -rf . || true
          
          # Copy new artifacts
          cp -r artifacts_permanent/* .
          
          # Commit and push
          git add .
          git commit -m "ü§ñ Auto-commit: Training artifacts from run ${{ github.run_id }}" || echo "No changes to commit"
          git push origin artifacts --force

  notify:
    name: Notification
    needs: [train, evaluate]
    runs-on: ubuntu-latest
    if: always()
    
    steps:
      - name: Training Success Notification
        if: needs.train.result == 'success' && needs.evaluate.result == 'success'
        run: |
          echo "‚úÖ All models trained successfully!"
          echo "üìä Evaluation completed!"
      
      - name: Training Failure Notification
        if: needs.train.result == 'failure' || needs.evaluate.result == 'failure'
        run: |
          echo "‚ùå Training or evaluation failed!"
          echo "Please check the logs for details."
          exit 1
