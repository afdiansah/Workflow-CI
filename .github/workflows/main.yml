name: ML Training Pipeline (MLflow Project)

on:
  push:
    branches:
      - main
      - develop
    paths:
      - 'MLProject/**'
      - '.github/workflows/main.yml'
  pull_request:
    branches:
      - main
      - develop
    paths:
      - 'MLProject/**'
  workflow_dispatch:

permissions:
  contents: write
  actions: read

jobs:
  train:
    name: Train ML Models with MLflow
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        model: [
          'Logistic_Regression',
          'Random_Forest',
          'Gradient_Boosting',
          'Decision_Tree',
          'K_Nearest_Neighbors',
          'Support_Vector_Machine'
        ]
      fail-fast: false
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python 3.12.7
        uses: actions/setup-python@v5
        with:
          python-version: '3.12.7'
      
      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('MLProject/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install MLflow and dependencies
        run: |
          python -m pip install --upgrade pip
          pip install mlflow>=2.0.0
          pip install -r MLProject/requirements.txt
      
      - name: Verify MLProject configuration
        run: |
          echo "üìã Checking MLProject file..."
          if [ ! -f "MLProject/MLproject" ]; then
            echo "‚ùå MLproject file not found!"
            exit 1
          fi
          echo "‚úÖ MLproject file found"
          cat MLProject/MLproject
          
          echo ""
          echo "üìä Checking dataset..."
          if [ ! -f "MLProject/Heart_Disease_preprocessing.csv" ]; then
            echo "‚ùå Dataset not found!"
            exit 1
          fi
          echo "‚úÖ Dataset found"
      
      - name: Run MLflow Project - ${{ matrix.model }}
        run: |
          echo "üöÄ Running MLflow Project for model: ${{ matrix.model }}"
          cd MLProject
          RUN_ID=$(mlflow run . -P model=${{ matrix.model }} --env-manager=local 2>&1 | tee /dev/stderr | grep -oP 'Run ID: \K[a-f0-9]+' | tail -1)
          echo "‚úÖ Training completed with Run ID: $RUN_ID"
          echo "RUN_ID=$RUN_ID" >> $GITHUB_ENV
        env:
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
          MLFLOW_TRACKING_USERNAME: ${{ secrets.MLFLOW_TRACKING_USERNAME }}
          MLFLOW_TRACKING_PASSWORD: ${{ secrets.MLFLOW_TRACKING_PASSWORD }}
      
      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: model-${{ matrix.model }}
          path: |
            MLProject/mlruns/
            MLProject/model_comparison_results.csv
          retention-days: 30
          if-no-files-found: ignore

  evaluate:
    name: Evaluate Models
    needs: train
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12.7'
      
      - name: Install dependencies
        run: pip install pandas
      
      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/
      
      - name: Compare results
        run: |
          python -c "
          import pandas as pd
          import glob
          
          csv_files = glob.glob('artifacts/**/model_comparison_results.csv', recursive=True)
          
          if csv_files:
              dfs = [pd.read_csv(f) for f in csv_files]
              combined = pd.concat(dfs, ignore_index=True).sort_values('test_accuracy', ascending=False)
              
              print('='*70)
              print('üìä MODEL COMPARISON RESULTS')
              print('='*70)
              print(combined.to_string(index=False))
              print('='*70)
              
              combined.to_csv('final_results.csv', index=False)
              
              best = combined.iloc[0]
              print(f\"\\nüèÜ BEST MODEL: {best['model']}\")
              print(f\"   Accuracy: {best['test_accuracy']:.4f}\")
              print(f\"   F1-Score: {best['test_f1_score']:.4f}\")
          else:
              print('‚ùå No results found!')
              exit(1)
          "
      
      - name: Upload final results
        uses: actions/upload-artifact@v4
        with:
          name: final-results
          path: final_results.csv
          retention-days: 90
      
      - name: Create summary
        run: |
          echo "## üéØ MLflow Project Training Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Training Method: \`mlflow run\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "final_results.csv" ]; then
            echo "### üìä Performance:" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            cat final_results.csv >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi

  notify:
    name: Pipeline Status
    needs: [train, evaluate]
    runs-on: ubuntu-latest
    if: always()
    
    steps:
      - name: Success notification
        if: needs.train.result == 'success' && needs.evaluate.result == 'success'
        run: |
          echo "‚úÖ All models trained successfully using MLflow Project!"
          echo "üìä Results available in artifacts"
      
      - name: Failure notification
        if: needs.train.result == 'failure' || needs.evaluate.result == 'failure'
        run: |
          echo "‚ùå Pipeline failed!"
          exit 1
