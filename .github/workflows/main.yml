name: ML Training Pipeline

on:
  push:
    branches:
      - main
      - develop
    paths:
      - 'MLProject/**'
      - '.github/workflows/main.yml'
  pull_request:
    branches:
      - main
      - develop
    paths:
      - 'MLProject/**'
  workflow_dispatch:
    inputs:
      model_type:
        description: 'Model to train (all, Logistic_Regression, Random_Forest, Gradient_Boosting, Decision_Tree, K_Nearest_Neighbors, Support_Vector_Machine)'
        required: false
        default: 'all'

permissions:
  contents: write
  actions: read

jobs:
  setup:
    name: Setup Environment
    runs-on: ubuntu-latest
    outputs:
      python-version: ${{ steps.setup-python.outputs.python-version }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python 3.12.7
        id: setup-python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12.7'
      
      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('MLProject/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r MLProject/requirements.txt
      
      - name: Verify dataset
        run: |
          if [ ! -f "MLProject/Heart_Disease_preprocessing.csv" ]; then
            echo "‚ùå Dataset not found!"
            exit 1
          fi
          echo "‚úÖ Dataset found"
          python -c "import pandas as pd; df = pd.read_csv('MLProject/Heart_Disease_preprocessing.csv'); print(f'Dataset shape: {df.shape}')"

  train:
    name: Train ML Models
    needs: setup
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        model: [
          'Logistic_Regression',
          'Random_Forest',
          'Gradient_Boosting',
          'Decision_Tree',
          'K_Nearest_Neighbors',
          'Support_Vector_Machine'
        ]
      fail-fast: false
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python 3.12.7
        uses: actions/setup-python@v5
        with:
          python-version: '3.12.7'
      
      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('MLProject/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install mlflow
          pip install -r MLProject/requirements.txt
      
      - name: Verify files before training
        run: |
          echo "üìã Checking required files..."
          ls -la MLProject/
          if [ ! -f "MLProject/MLproject" ]; then
            echo "‚ùå MLproject file not found!"
            exit 1
          fi
          if [ ! -f "MLProject/Heart_Disease_preprocessing.csv" ]; then
            echo "‚ùå Dataset not found!"
            exit 1
          fi
          echo "‚úÖ All required files found"
      
      - name: Train model - ${{ matrix.model }}
        run: |
          cd MLProject
          echo "üöÄ Starting training for: ${{ matrix.model }}"
          echo "$(date '+%Y-%m-%d %H:%M:%S') - Starting MLflow training for ${{ matrix.model }}" > training_${{ matrix.model }}.log
          mlflow run . -P model_type=${{ matrix.model }} --env-manager=local 2>&1 | tee -a training_${{ matrix.model }}.log
          echo "$(date '+%Y-%m-%d %H:%M:%S') - Training completed for ${{ matrix.model }}" >> training_${{ matrix.model }}.log
        env:
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
          MLFLOW_TRACKING_USERNAME: ${{ secrets.MLFLOW_TRACKING_USERNAME }}
          MLFLOW_TRACKING_PASSWORD: ${{ secrets.MLFLOW_TRACKING_PASSWORD }}
      
      - name: Verify artifacts after training
        run: |
          echo "üì¶ Checking generated artifacts..."
          echo ""
          echo "üìÅ MLProject directory:"
          ls -la MLProject/ || true
          echo ""
          echo "üìÅ MLProject/mlruns directory:"
          ls -la MLProject/mlruns/ || true
          echo ""
          echo "üìÅ MLProject/mlruns/0 directory (experiment):"
          ls -la MLProject/mlruns/0/ 2>/dev/null || echo "No experiment found"
          echo ""
          if [ -f "MLProject/training_${{ matrix.model }}.log" ]; then
            echo "‚úÖ Log file found"
            echo "Last 10 lines of log:"
            tail -n 10 MLProject/training_${{ matrix.model }}.log
          fi
      
      - name: Upload model artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: model-${{ matrix.model }}
          path: MLProject/mlruns/
          retention-days: 30
          if-no-files-found: warn
      
      - name: Upload training logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: logs-${{ matrix.model }}
          path: MLProject/training_${{ matrix.model }}.log
          retention-days: 7
          if-no-files-found: warn

  evaluate:
    name: Evaluate and Compare Models
    needs: train
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python 3.12.7
        uses: actions/setup-python@v5
        with:
          python-version: '3.12.7'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install mlflow pandas numpy matplotlib seaborn
      
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/
      
      - name: Extract metrics from MLflow runs
        run: |
          python -c "
          import mlflow
          import pandas as pd
          import glob
          import os
          
          print('='*70)
          print('üìä EXTRACTING METRICS FROM MLFLOW RUNS')
          print('='*70)
          
          # Find all model artifact directories (langsung dari artifacts/model-*)
          model_dirs = glob.glob('artifacts/model-*')
          
          print(f'\\nüìÇ Found {len(model_dirs)} model directories:')
          for d in model_dirs:
              print(f'   - {d}')
          
          all_results = []
          
          for model_dir in model_dirs:
              print(f'\\nüìÇ Processing: {model_dir}')
              
              # Set tracking URI langsung ke model directory
              tracking_uri = f'file:///{os.path.abspath(model_dir)}'
              mlflow.set_tracking_uri(tracking_uri)
              
              print(f'   Tracking URI: {tracking_uri}')
              
              # Get client
              client = mlflow.tracking.MlflowClient()
              
              # List all experiments
              try:
                  experiments = client.search_experiments()
                  print(f'   Found {len(experiments)} experiments')
              except Exception as e:
                  print(f'   ‚ö†Ô∏è Error listing experiments: {e}')
                  continue
              
              for exp in experiments:
                  if exp.lifecycle_stage == 'deleted':
                      continue
                      
                  print(f'   ‚úÖ Experiment: {exp.name} (ID: {exp.experiment_id})')
                  
                  # Search all runs in this experiment
                  try:
                      runs = client.search_runs(
                          experiment_ids=[exp.experiment_id],
                          order_by=['start_time DESC']
                      )
                      print(f'      Found {len(runs)} runs')
                  except Exception as e:
                      print(f'      ‚ö†Ô∏è Error searching runs: {e}')
                      continue
                  
                  for run in runs:
                      run_name = run.data.tags.get('mlflow.runName', 'Unknown')
                      metrics = run.data.metrics
                      
                      print(f'      üìä Run: {run_name}')
                      print(f'         Metrics: {metrics}')
                      
                      # Extract metrics
                      result = {
                          'model': run_name,
                          'test_accuracy': metrics.get('test_accuracy', 0),
                          'test_precision': metrics.get('test_precision', 0),
                          'test_recall': metrics.get('test_recall', 0),
                          'test_f1_score': metrics.get('test_f1_score', 0),
                          'run_id': run.info.run_id
                      }
                      all_results.append(result)
                      print(f'         Accuracy: {result[\"test_accuracy\"]:.4f}')
          
          # Create DataFrame
          if all_results:
              df = pd.DataFrame(all_results)
              
              # Remove duplicates (keep best accuracy for each model)
              df = df.sort_values('test_accuracy', ascending=False)
              df = df.drop_duplicates(subset=['model'], keep='first')
              
              print('\\n' + '='*70)
              print('üìä MODEL COMPARISON FROM MLFLOW RUNS')
              print('='*70)
              print(df.to_string(index=False))
              print('='*70)
              
              # Save results
              df.to_csv('final_model_comparison.csv', index=False)
              print('\\n‚úÖ Results saved to: final_model_comparison.csv')
              
              # Best model
              best = df.iloc[0]
              print(f\"\\nüèÜ BEST MODEL: {best['model']}\")
              print(f\"   Accuracy: {best['test_accuracy']:.4f}\")
              print(f\"   Precision: {best['test_precision']:.4f}\")
              print(f\"   Recall: {best['test_recall']:.4f}\")
              print(f\"   F1-Score: {best['test_f1_score']:.4f}\")
              print(f\"   Run ID: {best['run_id']}\")
          else:
              print('\\n‚ùå No MLflow runs found!')
              print('\\nüîç Troubleshooting:')
              print('   1. Check if model directories exist in artifacts')
              print('   2. Verify MLflow tracking was successful during training')
              print('   3. Check training logs for errors')
              exit(1)
          "
      
      - name: Upload final comparison
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: final-comparison
          path: final_model_comparison.csv
          retention-days: 90
          if-no-files-found: warn
      
      - name: Create summary
        run: |
          echo "## üéØ ML Training Pipeline Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Models Trained:" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Logistic Regression" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Random Forest" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Gradient Boosting" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Decision Tree" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ K-Nearest Neighbors" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Support Vector Machine" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "final_model_comparison.csv" ]; then
            echo "### üìä Model Performance:" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            cat final_model_comparison.csv >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: Prepare artifacts for commit
        run: |
          mkdir -p artifacts_permanent
          
          # Copy final comparison
          if [ -f "final_model_comparison.csv" ]; then
            cp final_model_comparison.csv artifacts_permanent/
          fi
          
          # Copy all downloaded artifacts
          if [ -d "artifacts" ]; then
            cp -r artifacts/* artifacts_permanent/
          fi
          
          # Create timestamp and metadata
          echo "# Training Run - $(date '+%Y-%m-%d %H:%M:%S')" > artifacts_permanent/README.md
          echo "" >> artifacts_permanent/README.md
          echo "**Commit:** ${{ github.sha }}" >> artifacts_permanent/README.md
          echo "**Branch:** ${{ github.ref_name }}" >> artifacts_permanent/README.md
          echo "**Workflow:** ${{ github.run_id }}" >> artifacts_permanent/README.md
          echo "**Triggered by:** ${{ github.actor }}" >> artifacts_permanent/README.md
          echo "" >> artifacts_permanent/README.md
          echo "## Results" >> artifacts_permanent/README.md
          if [ -f "final_model_comparison.csv" ]; then
            echo '```' >> artifacts_permanent/README.md
            cat final_model_comparison.csv >> artifacts_permanent/README.md
            echo '```' >> artifacts_permanent/README.md
          fi
      
      - name: Commit artifacts to artifacts branch
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          
          # Checkout or create artifacts branch
          git fetch origin artifacts || true
          git checkout -B artifacts || git checkout --orphan artifacts
          
          # Clear existing content (keep only new artifacts)
          git rm -rf . || true
           
          # Copy new artifacts
          cp -r artifacts_permanent/* . 2>/dev/null || echo "No artifacts to copy"
          
          # Commit and push with token
          git add . || true
          git commit -m "ü§ñ Auto-commit: Training artifacts from run ${{ github.run_id }}" || echo "No changes to commit"
          git push https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git artifacts --force || echo "Push failed"

  docker:
    name: Build and Push Docker Image
    needs: evaluate
    runs-on: ubuntu-latest
    if: success()
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Verify Docker Hub credentials
        run: |
          if [ -z "${{ secrets.DOCKERHUB_USERNAME }}" ]; then
            echo "‚ùå DOCKERHUB_USERNAME secret is not set!"
            echo "Please add it in: Repository ‚Üí Settings ‚Üí Secrets and variables ‚Üí Actions"
            echo ""
            echo "To skip Docker build, this is normal - training will still complete successfully."
            exit 1
          fi
          
          if [ -z "${{ secrets.DOCKER_PASSWORD }}" ]; then
            echo "‚ùå DOCKER_PASSWORD secret is not set!"
            echo "Please add it in: Repository ‚Üí Settings ‚Üí Secrets and variables ‚Üí Actions"
            echo ""
            echo "To skip Docker build, this is normal - training will still complete successfully."
            exit 1
          fi
          
          echo "‚úÖ Docker Hub credentials are configured"
      
      - name: Set up Python 3.12.7
        uses: actions/setup-python@v5
        with:
          python-version: '3.12.7'
      
      - name: Install MLflow
        run: |
          python -m pip install --upgrade pip
          pip install mlflow==2.19.0 boto3
      
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/
      
      - name: Find best model
        id: best-model
        run: |
          python -c "
          import pandas as pd
          import glob
          import os
          
          csv_files = glob.glob('artifacts/**/model_comparison_results.csv', recursive=True)
          
          if csv_files:
              dfs = [pd.read_csv(f) for f in csv_files]
              combined = pd.concat(dfs, ignore_index=True)
              combined = combined.sort_values('test_accuracy', ascending=False)
              
              best_model = combined.iloc[0]['model']
              best_accuracy = combined.iloc[0]['test_accuracy']
              
              # Sanitize model name for Docker tag
              model_tag = best_model.lower().replace('_', '-')
              
              print(f'Best model: {best_model}')
              print(f'Accuracy: {best_accuracy}')
              print(f'Docker tag: {model_tag}')
              
              # Write to GitHub output
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write(f'model_name={best_model}\n')
                  f.write(f'model_tag={model_tag}\n')
                  f.write(f'accuracy={best_accuracy}\n')
          else:
              print('No results found!')
              exit(1)
          "
      
      - name: Prepare model for Docker
        run: |
          MODEL_NAME="${{ steps.best-model.outputs.model_name }}"
          echo "üîß Preparing model: $MODEL_NAME"
          
          # Create directory for model
          mkdir -p model_to_deploy
          
          echo "üì¶ Extracting model artifacts..."
          # Find model artifacts from the specific model
          MODEL_ARTIFACT_DIR=$(find artifacts/model-${MODEL_NAME} -type d -path "*/artifacts/model" | head -1)
          
          if [ -z "$MODEL_ARTIFACT_DIR" ]; then
            echo "‚ùå Model artifacts not found for $MODEL_NAME"
            echo "Searching in all artifacts..."
            find artifacts -name "MLmodel" -type f
            exit 1
          fi
          
          echo "‚úÖ Found model at: $MODEL_ARTIFACT_DIR"
          
          # Copy model artifacts
          cp -r "$MODEL_ARTIFACT_DIR" model_to_deploy/
          
          echo ""
          echo "üìÇ Model structure:"
          ls -la model_to_deploy/model/
          
          echo ""
          echo "üìÑ MLmodel file:"
          cat model_to_deploy/model/MLmodel
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}
      
      - name: Build Docker image with MLflow
        env:
          MODEL_NAME: ${{ steps.best-model.outputs.model_name }}
          MODEL_TAG: ${{ steps.best-model.outputs.model_tag }}
          DOCKER_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
        run: |
          echo "üê≥ Building Docker image for: $MODEL_NAME"
          
          # Build Docker image using MLflow with local model path
          IMAGE_NAME="${DOCKER_USERNAME}/heart-disease-model"
          IMAGE_TAG="${MODEL_TAG}-$(date +%Y%m%d)"
          
          echo ""
          echo "üì¶ Image details:"
          echo "   Name: ${IMAGE_NAME}"
          echo "   Tag: ${IMAGE_TAG}"
          echo "   Model path: $(pwd)/model_to_deploy/model"
          
          # Build using local model path (not runs URI)
          echo ""
          echo "üî® Building Docker image..."
          mlflow models build-docker \
            --model-uri "$(pwd)/model_to_deploy/model" \
            --name "${IMAGE_NAME}"
          
          echo "‚úÖ Docker image built successfully"
          
          # Tag with version and latest
          echo ""
          echo "üè∑Ô∏è  Tagging images..."
          docker tag "${IMAGE_NAME}:latest" "${IMAGE_NAME}:${IMAGE_TAG}"
          docker tag "${IMAGE_NAME}:latest" "${IMAGE_NAME}:${MODEL_TAG}"
          
          echo "‚úÖ Tags created:"
          echo "   - ${IMAGE_NAME}:latest"
          echo "   - ${IMAGE_NAME}:${IMAGE_TAG}"
          echo "   - ${IMAGE_NAME}:${MODEL_TAG}"
          
          # Save to env for next step
          echo "IMAGE_NAME=${IMAGE_NAME}" >> $GITHUB_ENV
          echo "IMAGE_TAG=${IMAGE_TAG}" >> $GITHUB_ENV
      
      - name: Push Docker image to Docker Hub
        env:
          IMAGE_NAME: ${{ env.IMAGE_NAME }}
          IMAGE_TAG: ${{ env.IMAGE_TAG }}
          MODEL_TAG: ${{ steps.best-model.outputs.model_tag }}
        run: |
          echo "Pushing Docker images to Docker Hub..."
          
          # Push all tags
          docker push ${IMAGE_NAME}:latest
          docker push ${IMAGE_NAME}:${IMAGE_TAG}
          docker push ${IMAGE_NAME}:${MODEL_TAG}
          
          echo "‚úÖ Docker images pushed successfully!"
          echo "   - ${IMAGE_NAME}:latest"
          echo "   - ${IMAGE_NAME}:${IMAGE_TAG}"
          echo "   - ${IMAGE_NAME}:${MODEL_TAG}"
      
      - name: Create Docker summary
        env:
          IMAGE_NAME: ${{ env.IMAGE_NAME }}
          IMAGE_TAG: ${{ env.IMAGE_TAG }}
          MODEL_NAME: ${{ steps.best-model.outputs.model_name }}
          ACCURACY: ${{ steps.best-model.outputs.accuracy }}
        run: |
          echo "## üê≥ Docker Image Published" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Model:** ${MODEL_NAME}" >> $GITHUB_STEP_SUMMARY
          echo "**Accuracy:** ${ACCURACY}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Docker Images:" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "docker pull ${IMAGE_NAME}:latest" >> $GITHUB_STEP_SUMMARY
          echo "docker pull ${IMAGE_NAME}:${IMAGE_TAG}" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Run Container:" >> $GITHUB_STEP_SUMMARY
          echo '```bash' >> $GITHUB_STEP_SUMMARY
          echo "docker run -p 8080:8080 ${IMAGE_NAME}:latest" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

  notify:
    name: Notification
    needs: [train, evaluate, docker]
    runs-on: ubuntu-latest
    if: always()
    
    steps:
      - name: Training Success Notification
        if: needs.train.result == 'success' && needs.evaluate.result == 'success'
        run: |
          echo "‚úÖ All models trained successfully!"
          echo "üìä Evaluation completed!"
      
      - name: Docker Success Notification
        if: needs.docker.result == 'success'
        run: |
          echo "üê≥ Docker image pushed to Docker Hub!"
      
      - name: Docker Skipped Notification
        if: needs.docker.result == 'skipped'
        run: |
          echo "‚ö†Ô∏è Docker build was skipped"
          echo ""
          echo "Possible reasons:"
          echo "  1. DOCKER_USERNAME secret not set"
          echo "  2. DOCKER_PASSWORD secret not set"
          echo ""
          echo "To enable Docker deployment:"
          echo "  1. Go to: Repository ‚Üí Settings ‚Üí Secrets and variables ‚Üí Actions"
          echo "  2. Add secret: DOCKER_USERNAME (your Docker Hub username)"
          echo "  3. Add secret: DOCKER_PASSWORD (your Docker Hub access token)"
          echo ""
          echo "üìñ See DOCKER_SETUP.md for detailed instructions"
      
      - name: Training Failure Notification
        if: needs.train.result == 'failure' || needs.evaluate.result == 'failure'
        run: |
          echo "‚ùå Training or evaluation failed!"
          echo "Please check the logs for details."
          exit 1
      
      - name: Docker Failure Notification
        if: needs.docker.result == 'failure'
        run: |
          echo "‚ö†Ô∏è Docker build/push failed!"
          echo "Training was successful but Docker image not created."
          echo ""
          echo "Common issues:"
          echo "  1. Check DOCKER_USERNAME and DOCKER_PASSWORD secrets"
          echo "  2. Verify Docker Hub access token has correct permissions"
          echo "  3. Check Docker Hub storage quota"
          echo "  4. Review workflow logs for specific error"
